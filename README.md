State-of-the-art models for medical image segmentation achieve excellent accuracy but require substantial computational resources, limiting deployment in resource-constrained clinical settings. We present SegMate, an efficient 2.5D framework that achieves near-state-of-the-art accuracy, while drastically reducing computational requirements. Our efficient framework is the result of meticulously integrating asymmetric architectures, attention mechanisms, multi-scale feature fusion, and slice-based positional embeddings. Our key contributions are: (1) a novel dual-attention mechanism that combines lightweight Squeeze-Excitation (SE) blocks in nested decoder skip connections with Convolutional Block Attention Module (CBAM) modules in the main decoder path, achieving 39\% lower memory than standard U-Net; (2) a novel slice-position conditioning that improves cross-dataset generalization by +1.35\% Dice on out-of-distribution data; (3) a multi-task learning with boundary and presence heads that attains superior boundary precision (4.13mm HD95 vs 10.32mm, 60\% improvement).
We demonstrate the efficiency-accuracy trade-off of our framework across three modern backbones (EfficientNetV2-M, MambaOut-Tiny, FastViT-T12). On TotalSegmentator, we achieve a Dice score of 93.51\% with only 295MB peak GPU memory. Cross-dataset evaluations on SegThor and AMOS22 demonstrate strong generalization, with Dice scores of up to 85.90\% and 90.04\%, respectively.
